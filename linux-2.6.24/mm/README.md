# 内存管理

  从三个不同的视角，对内存进行逐步细化拆解。

## 虚拟内存、物理内存

### 物理内存

- 内存节点 node

  对于大型机器而言，内存会被分成许多簇，依据簇与处理器“距离”的不同，访问不同的簇所花费的代价（时间）也不同，每个簇都被认为是一个节点。

  - UMA 一致性内存访问

    系统中只存在一个内存节点，不同处理器到内存节点的访问时间相同，同一处理器到内存节点的不同区域的访问时间也相同。

  - [NUMA](https://blog.csdn.net/weixin_44246009/article/details/108655484) 非一致性内存访问

    系统内存在多个内存节点，不同处理器到同一内存节点的访问时间不相同，同一处理器到不同内存节点的访问时间也不相同，但同一处理器到同一内存节点的不同区域访问时间相同。

    [《The Free Lunch Is Over: A Fundamental Turn Toward Concurrency in Software》](http://www.gotw.ca/publications/concurrency-ddj.htm)

- 内存管理区 zone

  因实际的计算机体系结构有硬件的诸多限制，比如：80x86体系结构ISA总线的直接内存寻址DMA只能对RAM的前16MB寻址、具有大容量RAM的32位计算机中CPU无法直接通过逻辑地址线性映射到所有的物理地址等，从而限制了页框的使用方式，因此Linux内核把内存结点的物理内存划分成多个区域，对不同区域的内存需要采用不同的管理方式和映射机制。

  这里的内存区域就是指管理区，用于表示内存的某个范围。

  - 类别

    不同管理区类型适合不同类型的用途。

    80x86 UMA体系结构中管理区划分为：
    1、ZONE_DMA 包含低于16MB的内存页框；
    2、ZONE_NORMAL 包含高于16MB且低于896MB的内存页框；
    3、ZONE_HIGHMEM 包含从896MB开始高于896MB的内存页框。

    其中`ZONE_DMA`和`ZONE_NORMAL`区包含内存的“常规”页框，内核可以对其进行直接访问（内核启动时已对这类管理区完成页表的线性映射）；而`ZONE_HIGHMEM`包含的内存页不能由内核直接访问，其必须先被非线性映射到地址空间，才能被内核访问。

  - DMA zone

    低端范围的物理内存，用于外设直接内存访问。

    DMA是一种硬件机制，它允许外围设备和主内存之间直接传输它们的I/O数据，而不需要系统处理器的参与。使用这种机制可以大大提高与设备通信的吞吐量，因为免除了大量的计算开销。

  - Normal zone

    由内核直接映射到线性地址空间的较高部分。

  - Highmem zone

    高端内存，系统中预留的可用内存空间，不被内核直接映射。

    在访问特定的高端内存前，内核必须建立明确的虚拟映射，使该页可在内核地址空间中被防蚊贴，因此，许多内核数据结构必须被放置在低端内存中，而高端内存更趋向于为用户空间进程所保留。

  - 水位线

    每个管理区都存在三个极值，分别为pages_low、pages_min和pages_high，这些极值用于跟踪一个管理区承受了多大的压力，以此决定系统唤醒进程释放页面的频繁程度。

    - high watermark

      内存管理区高水位线，表示系统目前空闲内存充足，被唤醒释放内存的`kswapd`将再次睡眠。

    - low watermark

      内存管理区低水位线，表示系统空间内存紧张，到达该水位线时，会唤醒`kswapd`异步进行内存回收，直到内存重新回到high watermark水位线再将`kswapd`睡眠。

    - min watermark

      内存管理区最小水位线，低于该水位线时，表示系统空闲内存极度紧张，此时不再仅依靠kswapd异步回收内存，而是会在内存分配途中对内存进行同步回收，即伙伴分配器将以同步方式进行页面释放（direct-reclaim）。

      ![管理区水位线](https://raw.githubusercontent.com/Din2413/linux_comment/master/files/%E7%AE%A1%E7%90%86%E5%8C%BA%E6%B0%B4%E4%BD%8D%E7%BA%BF.png)

  - 保留页框池 min_free_kbytes

    内存分配请求在有足够的空闲内存可用的情况下，请求会被立刻得到满足；但当空闲内存短缺时，内核必须回收一些内存，同时将发出请求的内核控制路径阻塞，直到内存被释放。

    然而一些内核控制路径在请求内存时不能被阻塞，比如中断处理程序内或者执行临界区内的代码。在这些情况下，内核控制路径应当产生原子内存分配请求（`GFP_ATOMIC`内存分配标志）。原子请求从不被阻塞，如果没有足够的空闲页，则仅仅是分配失败而已。

    内核并不能保证一个原子内存分配请求绝不失败，但内核会设法尽量减少这种不幸事件的发生。为做到这一点，内核为原子内存分配请求保留了一个页框池，只有在内存不足时才使用。

    保留的页框池数量（以KB为单位）存放在`min_free_kbytes`变量中。该值取决于直接映射到内核线性地址空间的物理内存数量（低端内存大小）。且保留页框池也是由低端内存管理区的部分页框组成，高端内存页框使用前需按需构建内存映射，该过程可能需要请求分配新的页表进而因此阻塞。

    在系统初始化时会根据内存大小计算一个默认值，计算规则如下所示（**不同内核版本会存在差异**）：

    ```c
    /*
     * Initialise min_free_kbytes.
     *
     * For small machines we want it small (128k min).  For large machines
     * we want it large (64MB max).  But it is not linear, because network
     * bandwidth does not increase linearly with machine size.  We use
     *
     *      min_free_kbytes = 4 * sqrt(lowmem_kbytes), for better accuracy:
     *      min_free_kbytes = sqrt(lowmem_kbytes * 16)
     *
     * which yields
     *
     * 16MB:        512k
     * 32MB:        724k
     * 64MB:        1024k
     * 128MB:       1448k
     * 256MB:       2048k
     * 512MB:       2896k
     * 1024MB:      4096k
     * 2048MB:      5792k
     * 4096MB:      8192k
     * 8192MB:      11584k
     * 16384MB:     16384k
     */
     ```

    其中，**管理区的三个水位线是通过min_free_kbytes计算得到的**：其中，低端内存管理的watermark[min]为min_free_kbytes * (managed_pages(zone) / lowmem_pages)，而watermark[low]默认情况下为watermark[min] * 2，watermark[high]默认情况下为watermark[min] * 3。

    min_free_kbytes值越大，管理区水位线越高，同时三个水位线之间的差异也相应会增加。这意味着会较早的启动kswapd进行内存回收，且会回收较多的内存（直至high watermark才会停止），这会使得系统预留过多的空闲内存，从而在一定程度上降低了应用程序可使用的内存量。

    min_free_kbytes值越小，系统预留的内存就越小，同时管理区水位线越低，三个水位线之间的差异也相应减少。这意味着会导致内核频繁的进行直接内存回收（low watermark和min watermark之间差值很小，kswapd可能来不及回收到high watermark时空闲内存就从low降低到min），也就较容易阻塞应用程序，带来一定的响应延迟（程序卡顿）。

    ```c
    // watermark_scale_factor默认为10, 取值范围: 1 ~ 1000
    // 可以通过/proc/sys/vm/watermark_scale_factor设置
    int watermark_scale_factor = 10;

    // 设置每个zone的min, low和high水位
    static void __setup_per_zone_wmarks(void)
    {
      // 将总警戒水位值单位由kb转换为页数
      unsigned long pages_min = min_free_kbytes >> (PAGE_SHIFT - 10);

      ...

      tmp = (u64)pages_min * zone_managed_pages(zone);

      // 1. 相当于先计算zone->managed_pages占总managed_pages的比例;
      // 2. 然后将这个比例 * 总警戒水位, 得到此zone的警戒水位
      do_div(tmp, lowmem_pages);

      if (is_highmem(zone)) {
        /*
         * __GFP_HIGH and PF_MEMALLOC allocations usually don't
         * need highmem pages, so cap pages_min to a small
         * value here.
         *
         * The WMARK_HIGH-WMARK_LOW and (WMARK_LOW-WMARK_MIN)
         * deltas control asynch page reclaim, and so should
         * not be capped for highmem.
         */
        unsigned long min_pages;

        min_pages = zone_managed_pages(zone) / 1024;
        min_pages = clamp(min_pages, SWAP_CLUSTER_MAX, 128UL);
        zone->_watermark[WMARK_MIN] = min_pages;
      } else {
        /*
         * If it's a lowmem zone, reserve a number of pages
         * proportionate to the zone's size.
         */
        // 更新zone的警戒水位
        zone->_watermark[WMARK_MIN] = tmp;
      }

      /*
       * Set the kswapd watermarks distance according to the
       * scale factor in proportion to available memory, but
       * ensure a minimum size on small systems.
       */
      // 取以下两者之间的最大值
      // 1. 计算警戒水位的一半
      // 2. 计算zone->managed_pages的比例(0.1% ~ 10%), watermark_scale_factor越大tmp越大
      tmp = max_t(u64, tmp >> 2,
            mult_frac(zone_managed_pages(zone),
               watermark_scale_factor, 10000));

      // 低水位 = 警戒水位 + tmp
      zone->_watermark[WMARK_LOW]  = min_wmark_pages(zone) + tmp;
      // 高水位 = 警戒水位 + tmp * 2        
      zone->_watermark[WMARK_HIGH] = min_wmark_pages(zone) + tmp * 2;
      zone->watermark_boost = 0;

      ...
    }
    ```

- 物理页帧 page

  在管理区之上，系统内存进一步划分成大小确定的页面，通过页表与虚拟内存的页进行映射。
    
  ![内存节点](https://raw.githubusercontent.com/Din2413/linux_comment/master/files/%E5%86%85%E5%AD%98%E8%8A%82%E7%82%B9.png)

### 虚拟内存

虚拟内存可以让每个进程都有属于自己的虚拟地址空间。从用户角度来看，地址空间是一个平坦的线性地址空间（物理内存不一定，详见 [内存模型](https://zhuanlan.zhihu.com/p/68346347/)），由两部分组成：一个是随上下文切换而改变的用户空间部分，一个是保持不变的内核空间部分。

- 页表

  虚拟内存与物理内存之间的映射通过页表实现，一个虚拟内存页对应一个物理内存页框。为减少因存储页表而带来的内存消耗，Linux采样多级页表的形式维护虚拟内存到物理内存的映射关系。

  不同地址位数、不同类型的体系结构，所需采用的页表等级以及每个等级对应的bit位长度都可能存在差异。Linux采用四级分页模型，同时制定各种宏定义屏蔽体系结构差异，使得页表兼容不同的体系结构。

  四级分页模型四种页表分别为：页全局目录、页上级目录、页中间目录、页表；

  在四级分页模型中，页全局目录包含若干页上级目录的地址，页上级目录又依次包含若干页中间目录的地址，而页中间目录有包含若干页表的地址，每个页表项指向一个页框。在这种模型中，线性地址被分成五个部分，分别为“页全局目录偏移”、“页上级目录偏移”、“页中间目录偏移”、“页表项偏移”、“页框偏移”，每一部分的大小与具体的计算机体系结构有关。

  对于没有开启物理地址扩展的32位系统，二级页表足够使用。此时，Linux可将线性地址中的“页上级目录偏移”位和“页中间目录偏移”位设置为0，从根本上消除页上级目录和页中间目录字段。当需要采用三级页表实现虚拟内存转换时，也可采用类似方式将“页上级目录偏移”或“页中间目录偏移”位设置为0，以消除多余一级的页目录转换。

  ![页表映射](https://raw.githubusercontent.com/Din2413/linux_comment/master/files/%E9%A1%B5%E8%A1%A8%E6%98%A0%E5%B0%84.png)

- TLB缓存

  页表的级数越高，每次根据指定虚拟内存获取存储在真实物理内存中的数据所需要进行的访存操作也就越多，如三级页表获取指定虚拟地址对应的数据需要三次访存操作（①根据页全局目录偏移获取页中间目录表的物理地址②根据页中间目录偏移获取页表的物理地址③根据页框偏移获取所需数据）。

  因此，为减少虚拟地址到物理地址转换过程中访存次数，引入TLB（Translation Look-aside Buffer，地址变换高速缓存，简称快表）页表缓存机制减少访存操作，提高系统整体性能。

  但是，在带来性能提升的同时，TLB缓存也为系统带来了一定的复杂性和引入了一些问题（缓存一致性）。

## 内核空间、用户空间

![进程地址空间](https://github.com/Din2413/linux_comment/blob/bdca191ee5bbe8a0a6b1c8124563a6e90ea65ff8/files/%E5%9C%B0%E5%9D%80%E7%A9%BA%E9%97%B4.jpg)

### 内核空间

  uboot加载Linux内核时，通过bootargs启动参数的mem指定系统内存起始地址与大小，这个内存用于Linux内核和上层应用程序运行。mem之外的物理内存则留作他用，比如君正的rmem和nmem。

  依据平台特性，内核空间内存可能划分为两部分，即低端内存和高端内存。其中，高端内存在64位硬件或可用RAM较少的平台上是不需要存在的。

  低端内存包含“kernel image”、“reserved mem”和由伙伴系统管理的低端管理区。其中，“kernel image”为完成内核镜像启动所占用的内存空间，包含“kernel code”、“kernel data”、“init”等内存区域；“reserved mem”为内核启动时预留给特定模块使用的内存空间，模块启动时通过 bootmem 或者 memblock（内核启动时使用的内存管理器） 请求分配的内存区域。

- 低端内存

  在内核初始化时，会将低端内存直接线性映射到内核线性地址空间部分，后续内核可对这部分内存直接访问。

  线性地址X所映射的物理地址为：`X - PAGE_OFFSET`，其中`PAGE_OFFSET`为线性地址空间中内核空间起始地址。

- 高端内存

  为使内核能够使用系统内所有可用的RAM，需要将高端内存按需的映射到内核线性地址空间中的剩余部分（32位80x86体系结构中，映射到内核线性地址空间最后面的128MB），并在使用完成后解除映射，使得整个高端内存都能够在不同的时间被访问。

  但在64位硬件或可用RAM较少的平台上不存在这个问题，因为可使用的线性地址空间远大于能安装的RAM大小，简言之，这些情况下ZONE_HIGHMEM高端内存管理区总是空的。

  高端内存并不直接映射在内核线性地址空间部分，内核不能直接访问它们。

  内核提供三种不同的机制将高端内存映射到内核线性地址空间，分别叫做“动态映射”、“永久映射”及“临时映射”。其中，“永久映射”和“临时映射”占用的地址空间均比较小。
  
  - 动态映射

  动态内存映射用于在内核中分配虚拟内存连续但物理内存不一定连续的内存空间，可映射的线性地址空间范围为VMALLOC_START~VMALLOC_END，其通过vmalloc/vfree实现该类地址空间的分配和释放。

  一般服务于内核模块的加载。
  
  - 永久映射
  
    **永久内存映射使用内核页表中一个专门的页表**，该页表地址放在pkmap_page_table变量中，所映射的线性地址从PKMAP_BASE开始，页表的表项数由LAST_PKMAP宏产生，即**永久映射一次最多访问LAST_PKMAP * 4KB的高端内存**。

    永久内核映射的建立与撤销分别由kmap_high、kunmap_high两个函数实现。

    在获取页框对应的线性地址时，首先判断页框是否属于高端内存，如果不属于，则线性地址总是存在，且可以直接通过页框描述符计算页框下标，再转换成物理地址，最后根据物理地址得到线性地址，即__va((unsigned long)(page - mem_map) << 12)；如果属于，则先到永久映射关系的散列表查找，如果找到，则返回对应映射的线性地址，否则就调用kmap_high建立新的永久映射。

    为了记录高端内存页框与永久内核映射线性地址之间的联系，内核使用散列表记录包含“页框描述符地址”以及“页框永久映射线性地址”的元素。

    建立页框永久映射时，搜索专门页表pkmap_page_table中空闲页表项，将页框的物理地址写入该空闲页表项中，并创建一个新的映射关系对象添加进永久映射的散列表内。

    当永久内核映射页表项全部被映射时，建立新的永久映射的内核控制路径必须阻塞等待，直到永久内核映射页表中存在空闲页表项。因此，**建立永久内核映射可能阻塞当前进程，不能用在中断处理程序或可延迟函数等禁止阻塞的内核控制路径内**。
  
    具体实现可参照《深入理解linux内核(第三版)》-第八章内存管理-永久内核映射小节(308页)。
  
  - 临时映射
  
    临时内核映射也使用内核页表中的一个专门的页表，该页表地址存放在kmap_pte变量中，所映射的线性地址从FIXADDR_TOP自上而下开始。

    临时内核映射的建立与撤销分别由kmap_atomic、kunmap_atomic两个函数实现。

    高端内存的任一页框都可以通过一个“窗口”（为此而保留的一个页表项）映射到内核地址空间，不过留给临时内核映射的窗口数是非常少的。每个CPU都有 KM_TYPE_NR 个窗口的集合，用 enum km_type 数据结构表示，其中定义的每个符号，如KM_BOUNCE_READ、KM_PTE0等，标识了窗口的线性地址。

    可使用如下方法获取指定类型的临时映射对应的线性地址： `#define __fix_to_virt(x) (FIXADDR_TOP - ((x) << PAGE_SHIFT)) idx = type + KM_TYPE_NR*smp_processor_id(); vaddr = __fix_to_virt(FIX_KMAP_BEGIN + idx)`;

    临时内存映射比永久映射的实现要简单，此外，**建立临时内核映射不会阻塞当前进程，可以用在中断处理程序和可延迟函数等禁止阻塞的内核控制路径内部**。临时映射所占用的线性地址空间范围为FIXADDR_START~FIXADDR_TOP。

    不过缺点在于只有很少的临时内核映射可以同时建立起来，**使用临时内核映射的内核控制路径必须保证当前没有其他的内核控制路径在使用同样的映射**。
  
    ![内核空间内存映射](https://raw.githubusercontent.com/Din2413/linux_comment/master/files/%E5%86%85%E6%A0%B8%E7%A9%BA%E9%97%B4%E5%86%85%E5%AD%98%E6%98%A0%E5%B0%84.png)
    
    具体实现可参照《深入理解linux内核(第三版)》-第八章内存管理-临时内核映射小节(311页)。

### 用户空间

  内核地址空间是所有进程共享的，但用户地址空间是每个进程独享一份的，不过线程共享所属进程的用户地址空间。

  用户地址空间从上到下由环境变量区、命令行参数区、栈区、mmap映射区、堆区、bss区、data区以及text代码区等组成，其中bss区、data区、text代码区是可执行程序编译时生成的地址空间区域，而其他则是运行时产生的地址空间区域。

- 栈区 stack

  栈又称堆栈，由编译器自动分配释放，行为类似数据结构中的栈(先进后出、压栈退栈)。堆栈主要有三个用途：

  1、为函数内部声明的非静态局部变量提供存储空间；

  2、记录函数调用过程相关的维护性信息，称为栈帧(Stack Frame)或过程活动记录(Procedure Activation Record)。它包括函数返回地址，不适合装入寄存器的函数参数及一些寄存器值的保存；

 3、临时存储区，用于暂存长算术表达式部分计算结果或alloca()函数分配的栈内内存。

  进程内的每个线程都有属于自己的栈空间，向栈中不断压入数据时，若低于设置的堆栈最大空间（ulimit -s命令可查看和设置堆栈最大值，通常为8MB），则栈会动态增长（通过缺页异常扩展栈空间），程序继续运行，否则会触发栈溢出（Stack Overflow）异常。

  **数据出栈时，栈顶指针会相应的收缩，但收缩的只是栈虚拟地址空间，其映射的物理内存并不会收缩释放**。因此，调高堆栈容量可能会增加内存开销，并且程序开发时应注意避免递归调用的深度过大，以及采用动态分配的方式请求分配占用空间过大的局部变量。

- 映射区 mmap

  映射区是通过系统调用void *mmap(void *addr, size_t length, int prot, int flags, int fd, off_t offset);生成的，其内的每一段地址区域既可以映射到某一个文件（linux中一切皆文件，可以是实际磁盘文件或设备文件等），这种区域被称为**文件映射区**；也可以直接映射到物理内存区域，即不与任何文件关联，这种区域则被称为**匿名映射区**。

  除了文件关联性差异之外，映射区域在共享属性上也存在差异，其要么可在进程间共享，要么是进程私有的。因此，映射区域可以进一步细分成如下四种：

  1、**私有匿名映射区**：当使用参数 fd=-1 且 flags=MAP_ANONYMOUS | MAP_PRIVATE 时，创建的 mmap 映射是私有匿名映射，**私有匿名映射最常见的用途是在 glibc 分配大块内存中**，当需要的分配的内存大于 MMAP_THREASHOLD(128KB) 时，glibc会默认使用 mmap 代替 brk 来分配内存。

  2、**共享匿名映射区**：当使用参数 fd=-1 且 flags=MAP_ANONYMOUS | MAP_SHARED 时，创建的 mmap 映射是共享匿名映射。**共享匿名映射让相关进程共享一块内存区域，通常用于父子进程间通信**，子进程在fork之后继承映射，父子进程共享同样的物理页框，并且一个进程对映射内容的修改对其他进程可见。

  3、**私有文件映射区**：当使用参数 fd=有效文件描述符 且 flags = MAP_PRIVATE 时，创建的 mmap 映射是私有文件映射。**私有文件映射最常用的场景是加载动态共享库**，多个映射同一个文件的进程初始时会共享同样的物理内存页框，系统使用写时复制机制使得某个进程对映射内容的修改对其他进程不可见。

  4、**共享文件映射区**：当使用参数 fd=有效文件描述符 且 flags = MAP_SHARED 时，创建的 mmap 映射是共享文件映射。**共享文件映射常用的场景是读写文件和无关进程间通信**，前者将文件内容映射到进程地址空间，利用内核回写机制在映射内容被修改后同步回磁盘，其可以提高文件读写的效率（减少数据拷贝和系统调用次数）；后者使多个无关进程都同时映射一个相同的文件，一个进程对映射内容进行修改，另外的进程也能看到，以此实现多进程间的共享内存通信。

  在linux中，进程若通过malloc()请求一大块虚拟内存（超过阈值M_MMAP_THREASHOLD，缺省为128KB，可通过c库函数mallopt()调整），c运行时库并不会直接从堆内分配，而是创建一个私有匿名内存映射满足分配。当该块虚拟内存被free时，c运行时库也会相应地调用munmap对该匿名内存映射区域进行销毁，与此同时，与之映射的物理内存页框也会被释放。

- 堆区 heap

  堆区用于存放进程运行时动态分配的内存段（小于阈值M_MMAP_THREASHOLD），分配的堆内存段必须是经过字节对齐的（未对齐的数据访问会产生bus error异常）。

  堆区由堆内存分配器（如[ptmalloc](https://github.com/hustfisher/ptmalloc)、[tcmalloc](https://github.com/google/tcmalloc)等）进行管理，由应用程序动态分配和释放，**当堆分配器需要更多的虚拟内存以满足动态请求或者堆顶存在大量空闲内存时，可通过系统调用brk()或sbrk()来移动堆顶地址进行扩张或收缩**。

  若请求的内存未（忘记）被释放，用户进程便会出现内存“泄漏”，这段被“泄漏”的内存只有等待程序结束时才会被系统回收。但其实就算**请求的内存段被主动调用free()进行“释放”，可能也只是将该内存段占用的虚拟地址空间重新放回堆内存分配器的空闲列表中而已，与之映射的物理内存并不一定会被“回收”**。

  首先，堆内存可能是按照小字节进行分配的，而物理内存是按照页框单位进行分配的，堆分配器在需要时是以页为单位对堆虚拟内存进行映射的，只有当某个页的所有堆内存段被“释放”才表示该页映射的物理页框进入可回收状态。其次，堆内存的扩展和收缩都是通过移动堆顶地址进行的，被“释放”的堆内存段可能在堆非顶部区域，并且为了避免“堆顶频繁申请释放内存段时需要频繁地分配和释放物理页框”，堆内存分配器通常会限定“堆顶连续的空闲内存只有在大于某一个阈值（M_TRIM_THRESHOLD，缺省为128KB，可通过c库函数mallopt()调整）时才会对堆进行收缩回收”。

  由上可知，堆内存可能会出现“存在大量的已被释放内存段但都不处于堆顶导致无法被回收”的情况，也即是“内存空洞”的问题。如果想要消除“内存空洞”的影响，需要在申请和释放内存时，严格依照就近原则，最先释放堆顶地址的内存。但控制内存的申请和释放的顺序难度很大，且由于内部碎片的影响，每次申请得到的虚拟内存地址都带有一定的随机性，后面申请的内存，并不一定就意味着在堆顶，因此严格地做到内存从堆顶开始释放是不可能的。

- bss区

  bss区通常用于存放程序中未初始化或初值为0的全局变量和静态局部变量。

  bss区不占用物理文件空间，但程序运行时需为变量分配内存空间，故目标文件必须记录所有未初始化的静态分配变量大小总和。

- 数据区 data

  数据区通常用于存放程序中已初始化且初值不为0的全局变量和静态局部变量。数据段属于静态内存分配(静态存储区)，可读可写。

  与bss区不同的是，数据区占用物理文件，也占用内存空间，且当程序读取数据区的数据时，如果未被加载到内存空间，则会触发缺页异常。

- 代码区 text

  代码段也称正文段或文本段，通常用于存放程序执行代码。代码段是可共享的，频繁执行的程序只需要在内存中拥有一份拷贝即可，代码段通常属于只读，以防止其他程序意外地修改其指令。

## 内存分配、内存回收

### 内存分配

- 内存碎片

  “内存碎片”描述了一个系统中所有不可用的空闲内存，这些空闲内存较小且以不连续方式出现在物理内存的不同位置，内存分配器无法将这些内存利用起来分配给新的进程。

  以内存相对进程的所属位置进行划分，碎片内存可分成两种：一种为“外部碎片”，该种空闲碎片指的是还没有被分配出去，不属于任何进程的内存，由于内存太小而无法分配给申请连续内存空间的新进程；另外一种为“内部碎片”，该空闲碎片指的是已分配出去，属于某个进程但并不被使用的内存，由于内存被进程占有而无法被系统再利用，直到进程将其释放或进程结束；

  - 外部碎片

    “外部碎片”产生的原因是系统频繁的分配与回收物理页面导致大量的、不连续且小的页面块夹杂在已分配的页面中间。

    对于“外部碎片”的解决方案主要有两种：一种是**利用分页单元把一组非连续的空闲页框映射到连续的线性地址，即地址转换技术**；另一种则是开发一种适当的技术来记录现存的空闲连续页框块的情况，以避免为满足对小块的请求而分割大的空闲块，保证大块内存的连续性和完整性；

    第一种方式存在“用来映射非连续内存线性地址空间有限”、“每次映射都需要改写内核页表，导致内存分配速度大打折扣”的弊端。且在某些情况下，连续的页框确实是必要的，比如DMA处理器忽略分页单元而直接访问地址总线传送几个磁盘扇区的数据时。

    因此**Linux内核系统采用了第二种方案，即使用伙伴系统（buddy system）算法解决“外部碎片”问题。**

  - 内部碎片

    “内部碎片”产生的原因是内存分配必须起始于可被4、8或16整除的地址或者内存分配算法仅能把预定大小的内存分配给进程。

    对于“内部碎片”的解决方案其实与“外部碎片”类似，都是尽量保证内存按需分配，从恰当大小的内存池中对申请的内存进行分配，避免内存分配过大而造成空闲浪费。**Linux内核系统采用一种内存分配粒度较小的SLAB分配算法解决“内部碎片”问题**。

- 连续内存

  - 按页分配

    根据页框分配标志搜索一个能满足所请求的一组连续页框内存的管理区，并从中分配指定大小的页框块。

    ​	页框分配标注主要由两部分构成，一部分为`gfp_mask`，另一部分为`alloc_flags`。前者用于指定如何寻找、分配空闲页框，如`GFP_DMA/GFP_HIGHMEM`指定目标内存管理区、`GFP_ATOMIC/GFP_NOIO/GFP_NOFS`指定内存请求控制路径是否能被阻塞以及在可阻塞情况下是否允许换页回收内存；后者则用于指定如何进行水位线检查，如`ALLOC_NO_WATERMARKS`指定分配时不做水位线检查、`ALLOC_WMARK_MIN/LOW/HIGH`指定依次对最小/低/高水位进行检查，水位线检查失败则不满足分配。

    - 伙伴系统

      按页管理物理内存，系统内存分配基础，所有可用内存均需通过伙伴系统管理后提供上层请求分配。

      伙伴系统的宗旨就是用最小的内存块来满足内核对于内存的请求。**Linux伙伴系统把所有空闲页框分组为11个块链表，每个链表分别包含大小为1、2、4、8、16、32、64、128、256、512、1024个连续的页框**。每个块的第一个页框的物理地址是该块大小的整数倍（按块大小对齐）。

      假设需要申请256个页框的连续内存，伙伴系统算法首先在256个页框的链表中检查是否还有空闲块，如果有就分配出去。如果没有，算法会找到下一个更大的512页框的链表，如果存在空闲块，内核会把512页框分割成两部分，一半用来分配，另一半插入到256页框的链表中。如果依旧没有，则继续朝下一个具有更大数量页框的链表中查找，直到1024个页框的链表中也没有空闲块时，系统返回异常。

      同理，页框块在释放时，伙伴系统会将多个连续的页框块合并为一个较大的页框块。内核试图把大小为b的一对空闲伙伴块合并为一个大小为2b的单独块，并在成功后迭代进行。满足以下条件的两个块称为伙伴：①两个块具有相同的大小；②它们的物理地址是连续的；③**第一个块的第一个页框的物理地址是2\*b\*2^12的倍数**；

      ![伙伴系统](https://raw.githubusercontent.com/Din2413/linux_comment/master/files/%E4%BC%99%E4%BC%B4%E7%B3%BB%E7%BB%9F.png)

      具体实现可参照《深入理解linux内核(第三版)》-第八章内存管理-伙伴系统算法小节(311页) 或 mm/page_alloc.c源代码注释。

      - 反碎片技术-内存分类

        **伙伴系统仅仅寄托于内存释放时的合并操作而不考虑分配时的策略**，即伙伴系统的碎片防止机制寄托于内存使用者会及时释放掉内存的情况，但**当系统长期运行，或使用者长期不释放内存时，物理内存依然会产生很多碎片**。这些内存的存在，虽然对用户空间是没有影响的，因为用户态的内存是通过页面映射得到的；但对于内核态，碎片是个严肃的问题，因大部分物理内存都直接映射到内核的永久映射区。为了更进一步优化碎片问题，Linux内核引入**反碎片（anti-gragmentation）技术——内存分类**。

        Linux将内存大体分为三类：**不可移动页**（在内存的固定位置，不能移动带其他地方，内核态分配的内存属于该类型）、**可回收页**（不能直接移动，但可以删除）、**可移动页**（在内存中的位置可随便移动，只要修改对应表项就行，用户态应用程序使用的页属于该类型）。**相同阶的、不同类型的页框块采用不同的链表进行维护；当出现碎片情况时，可移动页面将会迁移，为申请者腾出所需的连续页面空间，由此避免空闲页面空间过于零碎而无法申请大块连续内存。**

      - 每CPU页框高速缓存

        为提高系统整体性能，用于快速满足对单个页框的分配请求。

        每个CPU为每个内存管理区提供两个高速缓存：

        1.  一个热高速缓存，表明其存放页框所包含的内容很可能在CPU硬件高速缓存中；
        2.  一个冷高速缓存，表明其存放页框所包含的内容不在CPU硬件高速缓存中；

        当请求的空闲内存块阶为0，即分配单页框时，可直接在'每CPU'页框高速缓存中分配；同理，释放单页框时，也直接放回‘每CPU’页框高速缓存中。当‘每CPU’高速缓存中无满足分配的页框或空闲页框达到某一上限值时，再向伙伴系统申请或释放一定数量的页框。

    - 后备管理区

      对于非一致性内存访问`UNMA`而言，除本地结点，还可能存在多个远端内存结点。当本地内存结点请求内存分配失败时，可选择最优的远端内存结点进行后备分配。

      内核引入后备管理区的概念，所有内存结点（本地内存结点或远端内存结点）内的、符合备选分配的管理区组成本地内存结点某类管理区的备选列表，当本地内存结点这类管理区的内存分配请求得不到满足时，可按序从备选列表中选择可用的管理区进行分配。

      依据不同的情况，内核提供两种备选列表的排列方式，第一种按结点顺序依次排列，先排列本地结点的所有ZONE，再排列其他结点的所有ZONE，该种排列方式更侧重内存分配结点的本地性，如：`highmem(node0)->normal(node0)->dma(node0)->highmem(node1)...`；第二种按ZONE类型从高到低依次排列，先排列各结点高类型ZONE，再排列各结点低类型ZONE，该种排列方式更侧重内存分配管理区类型的一致性，如：`highmem(node0)->highmem(node1)->normal(node0)->normal(node1)...`；

      每个内存结点包含`MAX_ZONELISTS`个备选分区列表，值为`2*MAX_NR_ZONES`，整个备选分区列表由两部分组成：

      -  前半部分`[0~MAX_NR_ZONES-1]`包含所有内存结点管理区列表，当自身管理区不满足分配时可从备选列表尝试分配
      -  后半部分`[MAX_NR_ZONES~MAX_ZONELISTS]`只包含自身结点管理区列表

      当限制内存分配只能从本地内存结点请求时，则直接使用后半部分的管理区列表，否则使用包含远端内存结点的管理区列表。

      系统中存在三个内存结点`node0/1/2`，每个内存结点包含`ZONE_DMA`、`ZONE_NORMAL`两个管理区，管理区排列方式采用`ZONELIST_ORDER_NODE`时，`node0`创建的`node_zonelists`各管理区的备用管理区列表如下所示：

      - `node_zonelists[ZONE_DMA] = ZONE_DMA(node0)->ZONE_DMA(node1)->ZONE_DMA(node2)；`
      - `node_zonelists[ZONE_NORMAL] = ZONE_NORMAL(node0)->ZONE_DMA(node0)->ZONE_NORMAL(node1)->ZONE_DMA(node1)->ZONE_NORMAL(node2)->ZONE_DMA(node2)；`
      - `node_zonelists[ZONE_DMA + MAX_NR_ZONES] = ZONE_DMA(node0)；`
      - `node_zonelists[ZONE_NORMAL + MAX_NR_ZONES] = ZONE_NORMAL(node0)->ZONE_DMA(node0)；`

  - 对象缓存

    **伙伴系统的最小分配单位为页框**，对于一些频繁申请/释放的小到几十字节的内存来说，直接采用伙伴系统进行内存分配显然是极其浪费且效率低下的。

    为缓解（通用对象缓存是按2的幂次方大小维护的，当请求的实际大小与2的幂次方大小不相等时，依然存在内部碎片浪费，只不过该机制可保证内部碎片小于50%）内存浪费以及低效问题，内核采用一种**建立在伙伴系统之上，以更小粒度和更高效的的方法**对小字节内存进行处理，该方法基于对象（所谓对象就是存放一组数据结构的内存区）进行管理，且以**对象提前分配与延迟释放**的方式提高小字节内存分配效率。

    该方法在对象请求分配时，提前从伙伴系统中请求分配以页框为单位的内存块，并将内存块划分成对象大小的缓存池，后续相同对象的请求分配可直接从缓存池中得到满足；同理，对象释放也采用类似策略，优先将对象放回缓存池，直到缓冲池中空闲数量较多或满足一定条件时，再将页框块重新释放回伙伴系统。

    - 对象类型

      高速缓存被分为两种类型：通用和专用。

      通用高速缓存在系统初始化期间创建，对象大小以2的幂次方几何分布，用于满足内核空间kmaloc/kfree对指定大小的内存分配请求。

      专用高速缓存是按需调用创建的，对象大小不具备任何规律，用于满足特定业务场景对特定数据结构的频繁分配和释放。

      - 通用对象缓存 kmalloc/kfree
      - 专用对象缓存 kmem_cache_alloc/kmem_cache_free

    - 分配算法

      内核提供三种可选的对象缓存分配器算法，分别为slab、slob、slub，Slab最初是Jeff Bonwick为Sun OS操作系统引入的一种算法，其围绕对象缓存为核心；Slub和Slob则是在slab的基础上针对特定场景的优化算法，前者主要针对大型机，而后者则是针对嵌入式系统等小型系统设计的。

      - slab分配器

        slab分配器把对象分组放进高速缓存，每个高速缓存都是同种类型对象的一种“储备”，包含高速缓存的主内存区被换分成多个slab，每个slab由一个或多个连续的页框组成。

        根据缓存对象的分配情况，slab被分成三种类型；包含空闲和非空闲对象的slab、只包含空闲对象的slab、不包含空闲对象的slab，不同的slab类型采用不同的链表维护。

        ![高速缓存与slab的关系](https://raw.githubusercontent.com/Din2413/linux_comment/master/files/%E9%AB%98%E9%80%9F%E7%BC%93%E5%AD%98%E4%B8%8Eslab%E7%9A%84%E5%85%B3%E7%B3%BB.png)

        一个新建的高速缓存并没有包含任何slab，即没有空闲的对象。当一个分配新对象的请求被发出且高速缓存不包含任何空闲对象时，slab分配器需从伙伴系统中请求分配一个新的slab（即一组连续的页框），用以补充缓存池。

        每个slab的缓存对象都是从某一个偏移位置开始依次排开的，为简单管理所有空闲的缓存对象，且在分配缓存对象时能尽快的获取缓存池中的空闲对象，**每个slab描述符内均包含一个用于描述空闲对象序列的整型数组。数组长度与slab缓存池中对象个数一致，每个元素包含当前slab中下一个空闲对象的序号index， 通过设置值为BUFCTL_END用以表示空闲对象链表的尾部，首个空闲对象的序号index则由slab描述的free字段保存，因此从free开始、以BUFCTL_END结尾可按序遍历slab内全部空闲对象。**。

        ![slab空闲对象数组](https://raw.githubusercontent.com/Din2413/linux_comment/master/files/slab%E7%A9%BA%E9%97%B2%E5%AF%B9%E8%B1%A1%E6%95%B0%E7%BB%84.png)

        理想状态下，slab的页框块应无缝隙的划分成独立的缓存对象，但这样就会使得缓存对象的起始地址极度不规则，而**内存单元的物理地址按照字大小（即计算机的内部内存总线的宽度）对齐，可增加内存单元的存取速度**；同理按照硬件高速缓存行对齐，避免横跨两个高速缓存行，也可提升数据的存取速度。这种机制虽然会适当地引入额外的内部碎片，但以空间换时间，可获得较好的高速缓存性能。

        **同一硬件高速缓存行可以映射RAM中很多不同的块，而缓存对象又会按字大小或硬件高速缓存行对齐，因此不同的slab内具有相同偏移量的对象最终很可能映射在同一硬件高速缓存行内**。高速缓存的硬件可能因此而花费内存周期在同一高速缓存行与RAM内存单元之间来来往往传送两个对象，而其他的高速缓存行并未充分使用。

        为尽量降低高速缓存的这种不愉快行为，slab分配器引入了一种叫做**slab着色**的策略，**把叫做颜色的不同随机数分配给不同slab的首个对象的起始偏移**。**颜色只是用来细分slab，具有不同颜色的slab把slab的第一个对象存放在不同的内存单元**。**可用颜色的个数与slab内空闲未用的字节free和硬件高速缓存行大小有关**（free/按硬件高速缓存行对齐的长度），只有当free足够大时，着色才起作用。不然空闲未用字节不足以容纳按硬件高速缓存行对齐的偏移长度，导致唯一可能着色的slab就是具有颜色0的slab，也就是把这个slab的第一个对象偏移量增加0个字节，即不起任何作用。

        ![slab着色](https://raw.githubusercontent.com/Din2413/linux_comment/master/files/slab%E7%9D%80%E8%89%B2.png)

        与伙伴系统每CPU页框高速缓存类似，为减少处理器之间对自旋锁的竞争并更好的理由硬件高速缓存，slab分配器的每个高速缓存包含一个被称作slab本地高速缓存的每CPU数据结构，该结构由**一个指向被释放对象的指针数组组成**。slab对象的大多数分配和释放只影响本地数组，只有在本地数组下溢或上溢时才涉及slab数据结构。

        **主要缺陷：**

        1、**复杂的队列管理机制**。在slab分配器中存在众多的队列，例如本地缓存队列、空闲/部分空闲/已满队列等，每个slab处于一个特定状态的队列之中，管理较复杂；

        2、**管理数据和队列的存储开销较大**。每个slab均需要一个slab描述符和管理空闲对象列表的整型数组，当对象体积较小时，该存储结构将造成较大的开销；

        3、**冗余的partial队列**。slab分配器针对每个节点都有一个partial队列，如果slab迎来一个分配高峰期，将有大量的partial slab产生。

        具体实现可参照《深入理解linux内核(第三版)》-第八章内存管理-slab分配器小节(324页) 或者 mm/slab.c源代码注释。

      - slob分配器

      - slub分配器

        slab是slob和slub实现的基础，而slob和slub是针对slab在不同场景下的优化版本。

        随着多处理器的发展和NUMA架构的广泛应用，slab的不足也逐渐显现。slab的缓存队列管理复杂，其用于管理的数据结构存储开销大，对NUMA支持复杂，slab着色机制效果不明显。

        这些不足让slab很难在两种场景下提供最优的性能：小型嵌入式系统和配备有大量物理内存的大规模并行系统。对于小型嵌入式系统来说，slab分配器的代码量和复杂性都太高；对于大规模并行系统，slab用于自身管理的数据结构就需要占用很多G字节内存。

        针对slab的不足，内核开发人员Christoph Lameter在内核版本2.6开发期间，引入了新的slub分配器。slub简化了slab一些复杂的设计，但保持slab的基本设计思想。同时，一种新的针对小型嵌入式系统的分配器slob也被引入，为了适应嵌入式系统的特点，slob进行了特别的优化，以大幅减少代码量（slob只有大约600行代码）。

- 非连续内存

  vmalloc/vfree

- malloc/free

- 延时分配

  初始只分配虚拟内存，将实际的物理内存分配推迟到真正需要访问时。

  虚拟内存状态:
  1.未分配；
  2.已分配、未映射；
  3.已映射、被换出不在内存中；
  4.已映射、在内存中；

- 写时复制

  最初创建子进程时，会对父进程做一次完全拷贝，这会增加不必要的内存拷贝工作，为解决该问题，引入写时复制机制。子进程只复制父进程的地址空间，而不拷贝实际的物理内存，且将共享内存写禁止，后续写时再通过缺页异常处理程序进行分配拷贝。

- 缺页异常

  因延迟分配、写时复制机制使得进程的虚拟内存可能并未与任何物理内存映射、或页权限与预期不匹配，当进程访问未映射的虚拟内存、或访问权限不匹配时，处理器会触发缺页异常，随后由缺页异常处理程序进行按需分页。

### 内存回收

- lru最近最少使用算法

  当内存不足时，淘汰系统中最近最少使用的内存，这样对系统性能的损耗才是最小的。

  为了准确找到可被回收的内存页，Linux内核维护了两个双向链表：**active_list和inactive_list**，用于管理用户空间相关的所有内存页，包含：所有匿名内存、映射的文件页、未映射的文件缓存页等，因此LRU最近最少使用算法其实是用于回收用户空间内存的，其不涉及内核空间内存回收（单独实现）。前者表示活跃内存页链表，存放最近被访问过的内存页；后者表示不活跃内存页链表，存放最近很少被访问的内存页。在内存回收时，应淘汰存放在后一个链表上的内存页。

  - active 活动链表

    从活动链表中筛选最近最少使用的页迁移至非活动链表

  - inactive 非活动链表

    从非活动链表中筛选内存页进行回收

- 回收机制

  - 缓存回收

    Linux内核将最近读取或写入磁盘的文件数据缓存在内存中（磁盘页高速缓存），以加快文件系统访问速度。在内存回收时，首先对该类文件缓存页进行回收处理，对未被修改过的文件页，内核直接回收其占用的页框，对被修改过还未被写回的“脏”页，内核将数据写回到磁盘后再将占用的页框进行回收。前者不涉及磁盘IO操作，而后者涉及，前者页框回收速度最快且对性能的影响最小。

  - 页面置换

    页面置换主要是将部分不可直接释放或不可写回到磁盘的内存页置换到交换空间上（反向映射、交换缓存），以便让系统不会因内存不够用而导致OOM或者更致命的情况出现。交换空间是RAM内存已满时使用的“硬盘”的一部分，交换空间可以是专用交换分区，也可以是交换文件。

    - swappiness

      swappiness是Linux内核属性，用于设置从匿名页换出到交换空间与从页面缓存中直接回收（匿名页与文件页）之间的平衡。swappiness的值可以在0到100之间。较低的值将使内核尽可能避免交换，而较高的值意味着内核将尝试更积极地使用交换空间。

    大多数Linux发行版的默认swappiness值为60，尽管对于大多数用户来说，交换值60是合适的。但在某些情况下，您可能需要设置一个较低的值。因为访问交换空间比直接访问物理内存要慢得多，较低的swappiness参数值将最有可能改善整体系统性能。

    更改swappiness值时应取决于您的系统工作负载和RAM内存的大小。

  - 内存压缩

    内存压缩使用内存页作为交换空间，在内存需要回收时将已占用内存压缩“置换”到内存交换空间内，根据压缩比换取部分空闲内存。比如 [zram](https://teawater.github.io/presentation/zram_zsmalloc.pdf) 算法。

  - 内存不足 [OOM](https://biscuitos.github.io/blog/OOM/)

    OOM (Out Of Memory) 机制为Linux内核中一种自我保护机制，当系统分配不出内存且无法回收时会触发这个机制，由系统在已有进程中挑选一个占用内存较多，回收内存收益最大的进程杀掉来释放内存。

## 后续课题
~~1.内存水位线:high、low、min、min_free_kbytes；</br>~~
~~2.内存映射:直接映射、动态映射、永久映射、临时映射；</br>~~
~~3.[系统内存占用分析方法论](https://github.com/Din2413/linux_comment/blob/master/linux-2.6.24/mm/memory_occupy.md)；</br>~~
~~4.内核空间内存分配:连续内存分配(伙伴系统、slab/slob/slub分配器)、非连续内存分配(vmalloc)；</br>~~
5.进程地址空间:延时分配、mmap映射(匿名映射、文件映射)、elf目标文件(格式分析)；</br>
6.写时复制、缺页异常；
7.内存回收:回收算法(扩展课题:磁盘页缓存、脏页回写)、交换分区/页面置换（换出、换入）、内存压缩、OOM；</br>
